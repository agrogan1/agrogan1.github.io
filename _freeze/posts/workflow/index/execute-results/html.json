{
  "hash": "2e699d93113458a527a5d8c24870172e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Workflow\"\nsubtitle: \"A Long-ish Post About Data Science / Data Analysis Workflow.\"\nauthor:  Andy Grogan-Kaylor\ndate: \"2026-2-15\"\nmermaid: \n  theme: default\n---\n\n\n::: {.cell}\n\n:::\n\n\n# Introduction\n\nI have increasingly been thinking about the idea of *workflow* in data science / data analysis work.\n\nSo many workflows follow the same conceptual pattern.\n\n# Visually and Conceptually\n\n```{mermaid}\n%%| fig-cap: \"A Common Data Workflow\"\n%%| fig-height: 7\n%%| label: fig-common-workflow\n%%{\n  init: {\n    'theme': 'base',\n    'themeVariables': {\n      'primaryColor': '#FFCB05',\n      'primaryTextColor': '#000000',\n      'primaryBorderColor': '#00274C',\n      'lineColor': '#00274C',\n      'secondaryColor': '#00274C',\n      'secondaryTextColor': '#000000',\n      'tertiaryColor': '#F2F2F2',\n      'tertiaryBorderColor': '#00274C'\n    }\n  }\n}%%\n\nflowchart TB\n\nask[ask a question]-->open\n\nopen[open the raw data]-->keep\n\nkeep[select or keep variables]-->clean\n\nclean[clean the data, e.g. outliers & errors]-->wrangle\n\nwrangle[create any new variables or scales]-->descriptives\n\ndescriptives[descriptive statistics]-->visualize\n\nvisualize[visualize the data]-->analyze\n\nanalyze[analyze with bivariate or multivariate statistics]-->share[\"share your results with your community(ies)\"]\n\n```\n\n# Characteristics of Good Workflows\n\nIncreasingly, we want to think about workflows that are \n\n* **documentable**, **transparent**, and **auditable**: We have a record of what we did if we want to double check our work, clarify a result, or develop a new project with a similar process. We, or others, can find the inevitable errors in our work, **and correct them**.\n* **replicable**: Others can replicate our findings with the same or new data.\n* **scalable**: We are developing a process that can be as easily used with *thousands* or *millions* of rows of data as it can with *ten* rows of data. We are developing a process that can be easily repeated if we are *constantly getting new or updated data*, e.g. getting new data every week, or every month.\n\n# Complex Workflows \n\nFor **complex workflows**, we will often want to write a script or code.\n\n::: {.callout-tip}\n## Complex Workflows Benefit From Scripts or Code\n\nThe more graphs or calculations I have to make, the more complex the project, the more the desires of the community or client are likely to change, the more frequently the data is being updated, the more team members that are involved in the workflow, and/or the more mission critical the results (i.e. I need auditability, documentation, and error correction) the more likely I am to use a scripting or coding tool like Stata or R.\n:::\n\n+---------------+---------------+--------------------+\n|               | Simple        | Complex Process:   |\n|               | Process:      | Multiple Graphs or |\n|               | Single Graph  | Calculations.      |\n|               | or            |                    |\n|               | Calculation   |                    |\n+===============+===============+====================+\n|**Process Run**| Spreadsheet:  | Scripting Tool:    |\n| **Only Once** | Excel or      | Stata or R         |\n|               | Google        |                    |\n+---------------+---------------+--------------------+\n| **Process**   | Scripting     | Scripting Tool:    |\n| **Run **      | Tool: Stata   | Stata or R         |\n| **Multiple**  | or R          |                    |\n| **Times**     |               |                    |\n|**(Perhaps As**|               |                    |\n| **Data Are**  |               |                    |\n| **Regularly** |               |                    |\n| **Updated)**  |               |                    |\n+---------------+---------------+--------------------+\n\n: Tools for Different Workflows {#tbl-tools}\n\n# Best Practices\n\n::: {.callout-tip}\n## Start With The Raw Data, Do Your Thinking In Code, And Document Your Thinking In Code\n\nAlways (or usually) beginning with the raw data, and then writing and running a script or code that generates our results allows us to develop a process that is **documentable**, **auditable**, **replicable** and **scalable**.\n:::\n\n::: {.callout-tip}\n## Data Are Often Best Stored In Statistical Formats\n\nIt is usually best to store quantitative data in a statistical format such as R, Stata, or SPSS. [Spreadsheets are likely to be a bad tool for storing quantitative data](https://agrogan1.github.io/posts/why-spreadsheets-are-a-bad-format-for-storing-data/).\n:::\n\n::: {.callout-important}\n## Good Workflows Require Safe Workspaces\n\nIt is also *very important* to be aware that good complex workflows are *highly iterative* and *highly collaborative*, often requiring *a lot of conversation*. Some--hopefully small--amount of error is *unavoidable* and *inevitable*. Good complex workflows require a *safe workspace* in which team members feel free to talk through their ideas, admit their own errors, and help with others' mistakes in a non-judgmental fashion. Such a *safe environment* is necessary to build an environment where the *overall error rate* is low.\n:::\n\n:::{.callout-important}\n## Good Workflows Require Patience And Can Be Psychologically Demanding\n\nDeveloping a good documented and auditable workflow that is implemented in code requires a lot of patience, and often, **many iterations**. Working through these many iterations can be psychologically demanding. It is important to remember that careful attention to getting the details right early in the research process, while sometimes tiring and frustrating, will pay large dividends later on when the research is reviewed, presented, published and read.\n:::\n\n# Example\n\nBelow is an example that uses the [Palmer Penguins](https://allisonhorst.github.io/palmerpenguins/) data set. \n\n::: {.callout-tip}\n## This Example is in Stata\n\nThe example below is in Stata, due to Stata's ease of readability, but could as easily be written in any other language that has scripting, such as SPSS, SAS, R, or Julia.\n:::\n\n\n::: {.cell}\n\n```{.stata .cell-code}\n\n* Learning About Penguins\n\n* Ask A Question\n\n* What can I learn about penguins?\n  \n```\n:::\n\n\n\n::: {.cell collectcode='true'}\n\n```{.stata .cell-code}\n\n* Open The Raw Data\n\nuse \"https://github.com/agrogan1/Stata/raw/main/do-files/penguins.dta\", clear \n\n* Clean and Wrangle Data\n\ngenerate big_penguin = body_mass_g > 4000 // create a big penguin variable\n\n```\n:::\n\n\n\n::: {.cell}\n\n```{.stata .cell-code}\n\n* Descriptive Statistics\n\nuse \"https://github.com/agrogan1/Stata/raw/main/do-files/penguins.dta\", clear\n\ndtable culmen_length_mm culmen_depth_mm flipper_length_mm body_mass_g i.species\n\n```\n\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRunning /Users/agrogan/Desktop/GitHub/agrogan1.github.io/posts/workflow/profile\n\n> .do ...\n\n\n\n\n-------------------------------------\n                        Summary      \n-------------------------------------\nN                                 344\nculmen_length_mm       43.922 (5.460)\nculmen_depth_mm        17.151 (1.975)\nflipper_length_mm    200.915 (14.062)\nbody_mass_g       4,201.754 (801.955)\nspecies                              \n  Adelie                  152 (44.2%)\n  Chinstrap                68 (19.8%)\n  Gentoo                  124 (36.0%)\n-------------------------------------\n```\n\n\n:::\n:::\n\n\n\n\n::: {.cell}\n\n```{.stata .cell-code}\n\n* Visualize The Data\n\nuse \"https://github.com/agrogan1/Stata/raw/main/do-files/penguins.dta\", clear\n\ngraph bar body_mass_g, over(species) // bar graph\n\nquietly graph export \"mybargraph.png\", replace\n\ntwoway scatter culmen_length_mm body_mass_g // scatterplot\n\nquietly graph export \"myscatterplot.png\", replace\n\n```\n\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRunning /Users/agrogan/Desktop/GitHub/agrogan1.github.io/posts/workflow/profile\n\n> .do ...\n```\n\n\n:::\n:::\n\n\n::: {layout=\"[[1,1]]\"}\n\n![Bar Graph of Penguin Species](mybargraph.png)\n\n![Scatterplot of Culmen Length by Body Mass](myscatterplot.png)\n\n:::\n\n\n::: {.cell}\n\n```{.stata .cell-code}\n\n* Analyze\n\nuse \"https://github.com/agrogan1/Stata/raw/main/do-files/penguins.dta\", clear\n\nquietly: regress culmen_length_mm body_mass_g // regress culmen length on body mass\n\nestimates store M1 // store these estimates\n\netable, estimates(M1) showstars showstarsnote // nice table of estimates\n\n```\n\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRunning /Users/agrogan/Desktop/GitHub/agrogan1.github.io/posts/workflow/profile\n\n> .do ...\n\n\n\n\n\n\n---------------------------------------\n                       culmen_length_mm\n---------------------------------------\nbody_mass_g                 0.004 **   \n                          (0.000)      \nIntercept                  26.899 **   \n                          (1.269)      \nNumber of observations        342      \n---------------------------------------\n** p<.01, * p<.05\n```\n\n\n:::\n:::\n\n\n\n# Multiple Person Workflows\n\nWhen workflows involve multiple people, all of the above considerations apply, but the situation often becomes more complex. Two hypothetical multiple person workflows are illustrated below. \n\nIn the diagram below, one workflow is *uncoordinated*. Each person's work is not available to the others, which may cause difficulties if people's work is supposed to build on the work of others. If one team member makes updates or corrects errors, the results of these efforts are not automatically available to the others.\n\nIn contrast, in the diagram below, one workflow is *coordinated*. Each person's work is available to the others so that updates and corrections to errors are propagated through the workflow, and into final analyses and visualizations. \n\nIt is often the case that a *coordinated* workflow requires more *coordination*, *time*, *energy*, and *patience* to implement than an *uncoordinated* workflow, but a *coordinated* workflow is likely to pay benefits in terms of all of the advantages of good workflows listed above. \n\n:::{.column-page}\n\n```{mermaid}\n%%| fig-cap: \"Complex Data Workflows\"\n%%| fig-width: 7\n%%| label: fig-complex-workflows\n%%{\n  init: {\n    'theme': 'base',\n    'themeVariables': {\n      'primaryColor': '#FFCB05',\n      'primaryTextColor': '#000000',\n      'primaryBorderColor': '#00274C',\n      'lineColor': '#00274C',\n      'secondaryColor': '#00274C',\n      'secondaryTextColor': '#000000',\n      'tertiaryColor': '#F2F2F2',\n      'tertiaryBorderColor': '#00274C'\n    }\n  }\n}%%\n\nflowchart TB \n\n%% first block: Uncoordinated Workflow\n\nrawdataA[raw data]\n\nrawdataB[raw data]\n\nperson1A[person 1]\n\nperson1B[person 1]\n\ncleandataA[cleans the data]\n\ncleandataB[cleans the data]\n\nperson2A[person 2]\n\nperson2B[person 2]\n\nscale1A[creates scale 1]\n\nscale1B[creates scale 1]\n\nperson3A[person 3]\n\nperson3B[person 3]\n\nscale2A[creates scale 2]\n\nscale2B[creates scale 2]\n\nperson4A[person 4]\n\nperson4B[person 4]\n\ncomplexanalysisA[complex analysis <br>and visualization]\n\ncomplexanalysisB[complex analysis <br>and visualization]\n\nsubgraph \"UNCOORDINATED Workflow\" \n\ndirection TB\n\nrawdataA-->person1A\n\nperson1A-->cleandataA\n\nrawdataA-->person2A\n\nperson2A-->scale1A\n\nrawdataA-->person3A\n\nperson3A-->scale2A\n\nrawdataA-->person4A\n\nperson4A-->complexanalysisA\n\nend\n\nsubgraph \"COORDINATED Multiperson Workflow\"\n\ndirection TB\n\nrawdataB-->person1B\n\nperson1B-->cleandataB\n\ncleandataB-->person2B\n\nperson2B-->scale1B\n\nscale1B-->person3B\n\nperson3B-->scale2B\n\nscale2B-->person4B\n\nperson4B-->complexanalysisB\n\nend\n\n```\n\n:::\n\n\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}