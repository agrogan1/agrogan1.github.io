{
  "hash": "b2de937b712bd77a725950699cc1b79c",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Be Less Wrong\"\nauthor: \"Andy Grogan-Kaylor\"\ndate: \"2024-12-17\"\ncategories: [science, social justice, stats]\nimage: \"math1.png\"\ndraft: true\n---\n\n\nThere are definite *realities* of abuse, neglect, suffering, exploitation, violence, discrimination, and other associated problems that we are trying to understand, and to reduce. \n\n> \"What we see and how we see is of course determined by our perspective, by the place from which we begin our examination of history; but it is determined also by reality itself.\" [@Martin-Baro1994B]\n\nWe hope that our research will inform efforts to change these *realities*. Yet, at the same time we must recognize that our understandings are at best *iterative* and *contingent.* While we will never have a perfect understanding of social reality, we can always improve our understandings, and move in the direction of being *less wrong*.\n\nAs @Silverman1998 wrote: \n\n> \"... there is no way to know when our observations about complex events in nature are complete. Our knowledge is finite, Karl Popper emphasised, but our ignorance is infinite. ... [W]e can never be certain about the consequences of our interventions, we can only narrow the area of uncertainty. This admission is not as pessimistic as it sounds: claims that resist repeated energetic challenges often turn out to be quite reliable. Such 'working truths' are the building blocks for the reasonably solid structures that support our everyday actions...\" [@Silverman1998]\n\nThis recalls the famous saying by the statistician George Box about statistical models, reported in many places, and well captured in the passage below by @Hand2014:\n\n> \"In general, when building statistical models, we must not forget that the aim is to understand something about the real world. Or predict, choose an action, make a decision, summarize evidence, and so on, but always about the real world, not an abstract mathematical world: our models are not the realityâ€”a point well made by George Box in his oft-cited remark that 'all models are wrong, but some are useful' (Box, 1979 in @MR0554183).\" [@Hand2014]\n\nA key task then, of using quantitative methods is to use them to try to be progressively *less wrong* about the answers we are finding to important questions about improving human wellbeing. \n\nLet's consider some simple visual models based upon some simulated data. Two key variables in this model are *intervention* (a treatment or program that we hope does some good), and the *outcome* (an improved or beneficial mental health or psychological outcome).\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n\nHere is a first model. What do these results say about the relationship of the *intervention* and the *outcome*?\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/fig-p0-1.png){#fig-p0 width=4200}\n:::\n:::\n\n\nThese simple straightforward results suggest that the *intervention* is associated with a worsening of the *outcome*.\n\n::: {.callout-important}\n## The Intervention is *Not* Recommended\n\nBased upon these results we would *not* recommend using this intervention.  \n:::\n\nLet's now consider a slightly more complex model. In addition to examining the *intervention* and the *outcome*, we account for the fact that individuals come from different *groups*. This could be any kind of group, e.g. a racial, ethnic, religious, cultural, or economic group. \n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/fig-p0-group-1.png){#fig-p0-group width=4200}\n:::\n:::\n\n\n::: {.callout-important}\n## The Intervention is Recommended\n\nOur conclusion seems to have flipped! Based upon these results we *would* recommend using this intervention.  \n:::\n\nThe fact that statistical results--and analogously visual results--can flip when more variables are accounted for is known as Simpson's Paradox [@Simpson1951]. Put briefly, and intuitively, our evidence based \"story\" can change--sometimes quite dramatically--as we add more and more factors to our model.[^multilevelstructure]\n\n[^multilevelstructure]: An analogous process can occur with multilevel data, in which there are often many groups. Failure to account for the grouping of the data can sometimes mean that our results are wrong, again sometimes quite dramatically [@Gelman2007; @Nieuwenhuis2015]. \n\n::: {.callout-tip}\n## Include As Many Relevant Variables As You Can\n\nFailure to include all of the relevant variables in our model--whether that model is visual or statistical--may lead to very wrong conclusions.\n\nIf those variables are observed, and included in our data set, it may be straightforward to build them into our model. If those variables are not observed, and not present in our data set, more complicated modeling strategies may be necessary.\n:::\n\nAt first the scenario I've just presented seems almost like a trick, or a puzzle, designed to confound us, or to illustrate a convoluted statistical scenario. Yet, upon reflection, the scenario I've just presented is surprisingly plausible. \n\n::: {.callout-tip}\n## A Thought Experiment\n\nImagine a situation in which an intervention is administered based upon the situation in a local community. Quite possibly, the intervention might be given in communities where outcomes are less good. At the same time the intervention might be beneficial to individuals. Such a scenario would present us with exactly the data that we see reflected in @fig-p0 and @fig-p0-group.\n:::\n\nLet's think about one more of these scenarios. For the sake of parsimony, this time I'm going to present the two graphs together. \n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/fig-p1-combined-1.png){#fig-p1-combined width=4200}\n:::\n:::\n\n\n::: {.callout-tip}\n## Be Less Wrong\n\nMy point? Simple models feel intuitive and have a commonsense appeal. Yet, with even slightly complicated social issues, simple models may be wrong.\n:::\n\nWhat I have illustrated here is only one set of ideas about how we need to complicate our quantitative thinking to try to be a little less wrong in thinking about social problems. Other more advanced statistical techniques may be seen as attempts to deal with other complications of the data, in an effort to be *less wrong*. \n\n\n\n\n\n\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}