{
  "hash": "3e3ce2264c0d75cad13e5fa70fbc5c97",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Exploring Data\"\nauthor: \"Andy Grogan-Kaylor\" \ndate: \"2025-9-7\"\ncategories: [stats, dataviz]\nimage: \"marginsplot2.png\"\n---\n\nIn [another post](../pairs-plots), I mentioned that for a few recent projects, I have had to quickly get up to speed on new data. In that other post, I focused on the idea of using a *pairs plot* in R. \n\nIn this post, I want to focus on a similar idea. But instead of a *pairs plot*, I focus on using a *regression model* with a number of risk and protective factors predicting an outcome. Here I use Stata instead of R, and use Stata's powerful `margins` and `marginsplot` command to get a visual idea of the way that these different risk and protective factors are associated with the outcome. \n\nUsing `margins` means that I'm going to use some complicated looking syntax to get some results that are actually pretty straightforward.\n\nFor this example, I use the data from my [Multilevel Workshop](https://agrogan1.github.io/multilevel-workshop/) site.\n\n\n\n::: {.cell}\n\n:::\n\n\n# Get The Data\n\n\n::: {.cell collectcode='true'}\n\n```{.stata .cell-code}\nuse simulated_multilevel_data.dta, clear\n\n```\n:::\n\n\n# Describe The Data\n\n\n::: {.cell}\n\n```{.stata .cell-code}\ndescribe\n\n```\n\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRunning /Users/agrogan/Desktop/GitHub/agrogan1.github.io/posts/exploring-data/profile\n\n> .do ...\n\n\n\nContains data from simulated_multilevel_data.dta\n Observations:         3,000                  \n    Variables:             9                  15 May 2024 14:54\n-------------------------------------------------------------------------------------\nVariable      Storage   Display    Value\n    name         type    format    label      Variable label\n-------------------------------------------------------------------------------------\ncountry         float   %9.0g                 country id\nHDI             float   %9.0g                 Human Development Index\nfamily          float   %9.0g                 family id\nid              str7    %9s                   unique country family id\nidentity        float   %9.0g                 hypothetical identity group variable\nintervention    float   %9.0g                 recieved intervention\nphysical_puni~t float   %9.0g                 physical punishment in past week\nwarmth          float   %9.0g                 parental warmth in past week\noutcome         float   %9.0g                 beneficial outcome\n-------------------------------------------------------------------------------------\nSorted by: country  family\n```\n\n\n:::\n:::\n\n\n# Regression Model\n\nBecause these data are clustered by country, I use the `mixed` command to get accurate standard errors and p values. \n\n\n::: {.cell collectcode='true'}\n\n```{.stata .cell-code}\nmixed outcome warmth physical_punishment i.intervention i.identity || country: \n  \n```\n:::\n\n\n::: {.callout-note collapse=\"true\"}\n## Show The Results\n\n\n::: {.cell collectcode='true'}\n::: {.cell-output .cell-output-stdout}\n\n```\nRunning /Users/agrogan/Desktop/GitHub/agrogan1.github.io/posts/exploring-data/profile\n\n> .do ...\n\n\n\nPerforming EM optimization ...\n\nPerforming gradient-based optimization: \nIteration 0:  Log likelihood = -9627.1393  \nIteration 1:  Log likelihood = -9627.1393  \n\nComputing standard errors ...\n\nMixed-effects ML regression                          Number of obs    =  3,000\nGroup variable: country                              Number of groups =     30\n                                                     Obs per group:\n                                                                  min =    100\n                                                                  avg =  100.0\n                                                                  max =    100\n                                                     Wald chi2(4)     = 373.21\nLog likelihood = -9627.1393                          Prob > chi2      = 0.0000\n\n------------------------------------------------------------------------------------\n           outcome | Coefficient  Std. err.      z    P>|z|     [95% conf. interval]\n-------------------+----------------------------------------------------------------\n            warmth |   .8342119   .0574661    14.52   0.000     .7215805    .9468434\nphysical_punishm~t |  -.9934352   .0798217   -12.45   0.000    -1.149883   -.8369874\n    1.intervention |   .6462874   .2175097     2.97   0.003     .2199762    1.072598\n        1.identity |  -.3104984   .2170594    -1.43   0.153    -.7359271    .1149302\n             _cons |   51.79936   .4777788   108.42   0.000     50.86293    52.73579\n------------------------------------------------------------------------------------\n\n------------------------------------------------------------------------------\n  Random-effects parameters  |   Estimate   Std. err.     [95% conf. interval]\n-----------------------------+------------------------------------------------\ncountry: Identity            |\n                  var(_cons) |   3.377381   .9627211      1.931725    5.904929\n-----------------------------+------------------------------------------------\n               var(Residual) |   35.04285   .9093623       33.3051    36.87127\n------------------------------------------------------------------------------\nLR test vs. linear model: chibar2(01) = 204.68        Prob >= chibar2 = 0.0000\n```\n\n\n:::\n:::\n\n\n:::\nWere the data not clustered, I could have just as easily used `regress`.\n\n\n::: {.cell}\n\n```{.stata .cell-code}\nregress outcome warmth physical_punishment i.intervention i.identity\n  \n```\n:::\n\n\n# Use `margins` to Get *Marginal Effects*\n\n`margins` in Stata is a very versatile (and sometimes confusing) command. Here I use slightly complicated syntax, to get a very simple set of results. I use `margins`, and the `dydx(*)` option to get marginal effects, which here are simply the $\\beta$ coefficients reported above.\n\n::: {.callout-tip collapse=\"false\"}\n## Why Go Through This Step?\n\nWe want to \"let `margins` know about the regression coefficients\".  \n\nAs we will see below, letting `margins` calculate the regression coefficients lets us graph the results using `marginsplot`.\n:::\n\n::: {.callout-tip collapse=\"true\"}\n## Technically Speaking...\n\nTechnically speaking, `dydx(*)` is asking Stata to calculate the marginal effects, $\\frac{\\partial y}{\\partial x}$ for all (`*`) independent variables in the model. In a linear model, with no interaction terms, $\\frac{\\partial y}{\\partial x} = \\beta$. \n\nAgain, we are essentially using slightly complicated syntax to get simple results. \n:::\n\n\n::: {.cell collectcode='true'}\n\n```{.stata .cell-code}\nmargins, dydx(*)\n\n```\n\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRunning /Users/agrogan/Desktop/GitHub/agrogan1.github.io/posts/exploring-data/profile\n\n> .do ...\n\n\n\nAverage marginal effects                                 Number of obs = 3,000\n\nExpression: Linear prediction, fixed portion, predict()\ndy/dx wrt:  warmth physical_punishment 1.intervention 1.identity\n\n------------------------------------------------------------------------------------\n                   |            Delta-method\n                   |      dy/dx   std. err.      z    P>|z|     [95% conf. interval]\n-------------------+----------------------------------------------------------------\n            warmth |   .8342119   .0574661    14.52   0.000     .7215805    .9468434\nphysical_punishm~t |  -.9934352   .0798217   -12.45   0.000    -1.149883   -.8369874\n    1.intervention |   .6462874   .2175097     2.97   0.003     .2199762    1.072598\n        1.identity |  -.3104984   .2170594    -1.43   0.153    -.7359271    .1149302\n------------------------------------------------------------------------------------\nNote: dy/dx for factor levels is the discrete change from the base level.\n```\n\n\n:::\n:::\n\n\n# Use `marginsplot` To Visualize the Marginal Effects\n\nFirst I use `marginsplot` with no options to visualize the marginal effects. This produces a pretty non-intuitive graph.\n\n\n::: {.cell}\n\n```{.stata .cell-code}\nmarginsplot\n\ngraph export \"marginsplot1.png\", replace\n\n```\n:::\n\n\n![`marginsplot` with default options](marginsplot1.png)\n\n# Use `marginsplot` With Better Options\n\nI add some options to clarify the graph. I `recast` the graph as a `scatter`plot. I flip the graph to be `horizontal`. I also add a reference line at $x = 0$ to make more clear which coefficients are significant, and which coefficients are not significant. \n\n\n::: {.cell}\n\n```{.stata .cell-code}\nmarginsplot, ///\nrecast(scatter) /// recast as scatterplot\nhorizontal /// flip to horizontal\nxline(0, lcolor(red)) // line at x = 0 in red\n\ngraph export \"marginsplot2.png\", replace\n  \n```\n:::\n\n\n![`marginsplot` with better options](marginsplot2.png)\n\n# Conclusion\n\nIn conclusion:\n\n1. I ran a regression model using `mixed` (I could have used `regress`). \n2. I transferred the values of the $\\beta$ regression coefficients to `margins`. \n3. I used `marginsplot` with a few options to see the results.\n\nThese steps: `mixed` or `regress`; `margins`; `marginsplot`, could be repeated for almost any analysis.\n\nResults suggest that `identity` is not associated with the `outcome`. The `intervention` is associated with improvements in the `outcome`. `physical_punishment` is associated with a worsened `outcome`. Parental `warmth` is associated with an improved `outcome`.\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}